# Comprehensive EventHub Monitoring Solution

This enhanced solution provides detailed monitoring of Azure EventHub consumption patterns with rich data classes, comprehensive lag analysis, and structured logging.

## üéØ Features

### Comprehensive Discovery & Monitoring
‚úÖ **Namespace Discovery** - Automatically discovers all EventHubs in namespace  
‚úÖ **Consumer Group Discovery** - Finds all consumer groups for each EventHub  
‚úÖ **Partition Analysis** - Monitors all partitions with sequence numbers and timestamps  
‚úÖ **Activity Monitoring** - Tracks partition activity and message flow patterns  
‚úÖ **Health Scoring** - Provides health scores and status for consumer groups  
‚úÖ **Parallel Processing** - Uses concurrent threads for fast monitoring  
‚úÖ **Message Production Rates** - Tracks message production rates per partition  
‚úÖ **Partition Activity Patterns** - Monitors which partitions are receiving messages  
‚úÖ **EventHub Utilization** - Measures total available messages and throughput  
‚úÖ **System Health Monitoring** - Verifies message flow and system responsiveness  

### Rich Data Classes & Structured Logging
‚úÖ **Data Classes** - Type-safe data classes for all metrics  
‚úÖ **Structured JSON Logs** - Application Insights ready logging  
‚úÖ **Comprehensive Metrics** - Namespace, EventHub, partition, and consumer group metrics  
‚úÖ **Activity Alerts** - Automatic alerts for inactive or erroring partitions  
‚úÖ **Performance Tracking** - Processing time and efficiency metrics  

### Advanced Analytics
‚úÖ **KQL Queries** - 10+ pre-built queries for Application Insights  
‚úÖ **Activity Dashboards** - Real-time activity and health monitoring  
‚úÖ **Trend Analysis** - Time-series analysis of message flow patterns  
‚úÖ **Error Detection** - Comprehensive error tracking and alerting  

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    EventHub Namespace                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  EventHub 1          ‚îÇ  EventHub 2          ‚îÇ  EventHub N      ‚îÇ
‚îÇ  ‚îú‚îÄ Partition 0      ‚îÇ  ‚îú‚îÄ Partition 0      ‚îÇ  ‚îú‚îÄ Partition 0  ‚îÇ
‚îÇ  ‚îú‚îÄ Partition 1      ‚îÇ  ‚îú‚îÄ Partition 1      ‚îÇ  ‚îú‚îÄ Partition 1  ‚îÇ
‚îÇ  ‚îî‚îÄ Partition N      ‚îÇ  ‚îî‚îÄ Partition N      ‚îÇ  ‚îî‚îÄ Partition N  ‚îÇ
‚îÇ                      ‚îÇ                      ‚îÇ                  ‚îÇ
‚îÇ  Consumer Groups:    ‚îÇ  Consumer Groups:    ‚îÇ  Consumer Groups:‚îÇ
‚îÇ  ‚îú‚îÄ $Default         ‚îÇ  ‚îú‚îÄ $Default         ‚îÇ  ‚îú‚îÄ $Default     ‚îÇ
‚îÇ  ‚îú‚îÄ cg-app-1         ‚îÇ  ‚îú‚îÄ cg-service-2     ‚îÇ  ‚îú‚îÄ cg-analytics ‚îÇ
‚îÇ  ‚îî‚îÄ cg-monitor       ‚îÇ  ‚îî‚îÄ cg-backup        ‚îÇ  ‚îî‚îÄ cg-audit     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Comprehensive Monitor                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îú‚îÄ Namespace Discovery (Management API)                       ‚îÇ
‚îÇ  ‚îú‚îÄ EventHub Discovery (Parallel Processing)                   ‚îÇ
‚îÇ  ‚îú‚îÄ Consumer Group Discovery (Per EventHub)                    ‚îÇ
‚îÇ  ‚îú‚îÄ Partition Metrics Collection                               ‚îÇ
‚îÇ  ‚îî‚îÄ Activity Analysis & Health Scoring                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                Structured Logging Output                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üìä NamespaceComprehensiveMetrics                              ‚îÇ
‚îÇ  üéØ EventHubComprehensiveMetrics                               ‚îÇ
‚îÇ  üë• ConsumerGroupActivityDetailed                              ‚îÇ
‚îÇ  üè• ActivityAlerts                                             ‚îÇ
‚îÇ  üìà MonitoringSummary                                          ‚îÇ
‚îÇ     ‚îÇ                                                         ‚îÇ
‚îÇ     ‚ñº                                                         ‚îÇ
‚îÇ  Application Insights ‚Üí KQL Queries ‚Üí Dashboards & Alerts    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìä Data Classes

### Core Metrics Classes

```python
@dataclass
class PartitionMetrics:
    namespace: str
    hub_name: str
    partition_id: str
    beginning_sequence_number: Optional[int] = None
    last_enqueued_sequence_number: Optional[int] = None
    last_enqueued_offset: Optional[str] = None
    last_enqueued_time_utc: Optional[datetime] = None
    is_empty: bool = True
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    
    # New calculated properties
    total_available_messages: Optional[int] = property
    retention_age_hours: Optional[float] = property
    has_recent_activity: bool = property

@dataclass
class ConsumerGroupLag:
    namespace: str
    hub_name: str
    consumer_group: str
    partition_id: str
    latest_sequence_number: Optional[int] = None
    current_sequence_number: Optional[int] = None
    sequence_lag: Optional[int] = None
    latest_offset: Optional[str] = None
    current_offset: Optional[str] = None
    time_lag_seconds: Optional[float] = None
    latest_enqueued_time: Optional[datetime] = None
    is_empty: bool = True
    error: Optional[str] = None
    lag_status: str = property  # ACTIVE, EMPTY, ERROR
    is_healthy: bool = property
```

## üöÄ Usage

### 1. Local Testing

```bash
# Set required environment variables
export EventHubConnectionString='Endpoint=sb://your-namespace.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=your-key'

# Set optional variables for full functionality
export SubscriptionId='your-subscription-id'
export ResourceGroup='your-resource-group'

# Run comprehensive monitoring test
python test_comprehensive_monitor.py

# Or run the exploration script directly
python LatestMessageMonitor/ehubExplore.py
```

### 2. Azure Function Deployment

The `ComprehensiveMonitorFunction` runs every 5 minutes and provides comprehensive monitoring:

```json
{
  "scriptFile": "__init__.py", 
  "bindings": [
    {
      "name": "timer",
      "type": "timerTrigger", 
      "direction": "in",
      "schedule": "0 */5 * * * *"
    }
  ],
  "timeout": "00:10:00"
}
```

### 3. Application Settings

Configure these in your Azure Function App:

| Setting | Required | Description |
|---------|----------|-------------|
| `EventHubConnectionString` | ‚úÖ | EventHub connection string |
| `SubscriptionId` | ‚ö™ | Azure subscription ID (for Management API) |
| `ResourceGroup` | ‚ö™ | Resource group name (for Management API) |
| `LOG_LEVEL` | ‚ö™ | Logging level (default: INFO) |

## üìà Monitoring Output

### Structured Log Types

#### 1. Namespace Overview
```json
{
  "eventType": "NamespaceComprehensiveMetrics",
  "timestamp": "2026-01-30T10:00:00Z",
  "namespace": "my-eventhub-ns",
  "discoveryMethod": "management_api",
  "totals": {
    "eventhubs": 3,
    "partitions": 12, 
    "consumerGroups": 8
  },
  "eventhubs": [...]
}
```

#### 2. Consumer Group Activity Details
```json
{
  "eventType": "ConsumerGroupActivityDetailed",
  "namespace": "my-eventhub-ns",
  "hubName": "orders-hub",
  "consumerGroup": "order-processor",
  "healthScore": 85.5,
  "aggregates": {
    "activePartitions": 3,
    "totalPartitions": 4,
    "emptyPartitions": 1,
    "errorPartitions": 0
  },
  "partitionDetails": [...]
}
```

#### 3. Activity Alerts
```json
{
  "eventType": "ActivityAlerts",
  "namespace": "my-eventhub-ns", 
  "alertCount": 2,
  "alerts": [
    {
      "severity": "WARNING",
      "eventhub": "payments-hub",
      "consumerGroup": "payment-processor",
      "healthScore": 45.0,
      "issue": "Multiple partitions showing errors"
    }
  ]
}
```

## üîç Application Insights Queries

### Quick Health Check
```kql
traces
| where timestamp > ago(30m)
| where message contains "Consumer Group Activity Detailed"
| extend logData = parse_json(substring(message, indexof(message, "{")))
| where todouble(logData.healthScore) < 70
| project 
    timestamp,
    hubName = logData.hubName,
    consumerGroup = logData.consumerGroup,
    healthScore = logData.healthScore,
    activePartitions = logData.aggregates.activePartitions,
    totalPartitions = logData.aggregates.totalPartitions
| order by healthScore asc
```

### Activity Trend Analysis
```kql
traces
| where timestamp > ago(4h)
| where message contains "Consumer Group Activity Detailed"
| extend logData = parse_json(substring(message, indexof(message, "{")))
| project 
    timestamp,
    hubName = tostring(logData.hubName),
    consumerGroup = tostring(logData.consumerGroup),
    activePartitions = tolong(logData.aggregates.activePartitions),
    totalPartitions = tolong(logData.aggregates.totalPartitions)
| summarize AvgActivePartitions = avg(activePartitions), 
    ActivityRate = (avg(activePartitions) * 100.0 / avg(totalPartitions))
    by hubName, consumerGroup, bin(timestamp, 15m)
| render timechart
```

## üö® Health & Alerting

### Health Score Calculation
- **90-100%**: ‚úÖ Healthy (all partitions active, no errors)
- **70-89%**: ‚ö†Ô∏è Warning (some partitions empty or minor issues)
- **0-69%**: ‚ùå Critical (multiple errors or most partitions inactive)

### Automated Alerts
- Consumer groups with health score < 70%
- Partitions with connection errors
- EventHubs with no recent activity
- Processing failures and timeouts

### Alert Categories
- üî¥ **CRITICAL**: Health < 50% or multiple partition errors
- ‚ö†Ô∏è **WARNING**: Health 50-69% or inactive partitions
- üìä **INFO**: Activity monitoring data and trends

## üõ†Ô∏è Troubleshooting

### Common Issues

1. **No EventHubs Discovered**
   - Check EventHub connection string
   - Verify namespace exists and is accessible
   - Set SubscriptionId and ResourceGroup for Management API

2. **Limited Consumer Group Discovery**
   - Management API not available ‚Üí only $Default consumer group found
   - Set SubscriptionId, ResourceGroup for full discovery

3. **Partition Connection Errors**
   - Network connectivity issues to EventHub
   - Invalid EventHub connection string
   - EventHub namespace not accessible

4. **High Processing Time**
   - Too many EventHubs/consumer groups
   - Network latency to EventHub
   - Reduce max_workers or implement throttling

### Performance Optimization

- **Parallel Processing**: Uses ThreadPoolExecutor for concurrent monitoring
- **Client Caching**: Reuses EventHub clients to avoid connection overhead
- **Efficient Partition Scanning**: Optimized partition property retrieval
- **Configurable Timeouts**: Optimized for fast execution

## üìö File Structure

```
ehub-monitoring-app/
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ comprehensive_monitor.py     # Core monitoring classes & logic
‚îÇ   ‚îú‚îÄ‚îÄ logging_config.py           # Centralized logging setup
‚îÇ   ‚îî‚îÄ‚îÄ ...                         # Existing utilities
‚îú‚îÄ‚îÄ ComprehensiveMonitorFunction/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 # Azure Function implementation
‚îÇ   ‚îî‚îÄ‚îÄ function.json              # Function configuration
‚îú‚îÄ‚îÄ LatestMessageMonitor/
‚îÇ   ‚îî‚îÄ‚îÄ ehubExplore.py             # Enhanced exploration script
‚îú‚îÄ‚îÄ kql/
‚îÇ   ‚îî‚îÄ‚îÄ comprehensive_monitoring.kql # 10+ KQL queries
‚îú‚îÄ‚îÄ test_comprehensive_monitor.py   # Local testing script
‚îú‚îÄ‚îÄ requirements.txt               # Updated dependencies
‚îî‚îÄ‚îÄ README_Comprehensive.md       # This documentation
```

## üîÑ Migration from Existing Solution

This comprehensive solution is fully backward compatible and enhances your existing monitoring:

1. **Existing Functions Continue Working** - No breaking changes
2. **Enhanced Logging** - Adds structured data classes and rich metrics
3. **New Timer Function** - `ComprehensiveMonitorFunction` for detailed analysis
4. **Improved Discovery** - Better EventHub and consumer group discovery
5. **Advanced Analytics** - KQL queries for deep insights

You can deploy the comprehensive solution alongside your existing functions for a gradual migration.

---

## üéâ What You Get

With this comprehensive EventHub monitoring solution, you now have:

‚úÖ **Complete Visibility** - Every EventHub, partition, and consumer group monitored  
‚úÖ **Rich Metrics** - Sequence numbers, offsets, timestamps, activity analysis  
‚úÖ **Health Insights** - Automated health scoring and alerting  
‚úÖ **Operational Excellence** - Structured logging for Application Insights  
‚úÖ **Advanced Analytics** - KQL queries for deep operational insights  
‚úÖ **Production Ready** - Parallel processing, error handling, performance optimized  

Your monitoring data is now production-ready for:
- Real-time operational dashboards
- Automated alerting and incident response  
- Capacity planning and performance optimization
- Compliance and audit reporting
- Troubleshooting and root cause analysis
